{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome!\n",
    "\n",
    "Welcome to the Zero to GPT course!  Over the next few lessons, you'll go from no deep learning knowledge to being able to train your own GPT model.\n",
    "\n",
    "At a high level, GPT works by predicting what words should come after your prompt.  If you prompt GPT-3 with `Write me a song about deep learning`, it returns something like this:\n",
    "\n",
    "```\n",
    "Verse 1:\n",
    "Deep learning is the way of the future,\n",
    "Data mining through layers of complexity\n",
    "Processing information with intelligence\n",
    "Where will this technology take us?\n",
    "```\n",
    "\n",
    "GPT models are also called deep learning models.  Deep learning is a subfield of machine learning, which is a subfield of AI.  In deep learning, we train a neural network composed of many layers to transform an input into an output.\n",
    "\n",
    "Neural networks can't understand text directly, so GPT has to convert your prompt to numbers, make predictions, then convert the predictions back to text.  The process works like this:\n",
    "\n",
    "1. Split your prompt up into tokens (tokens are similar to words), and convert each token to a vector of numbers\n",
    "2. Feed the vectors into a neural network\n",
    "3. Predict what vectors come after the input tokens\n",
    "4. Convert the vectors back into text\n",
    "\n",
    "Splitting the prompt into tokens, then converting the predictions back into text is called natural language processing (NLP).  NLP is how we can use computers to work with text.\n",
    "\n",
    "The key part of GPT is the third step, where the network predicts which tokens will come after the input tokens.  To do this, the network uses its parameters.  You can think of parameters like memory.  This memory has been trained on a lot of data (gigabytes or terabytes).  Parameters enable neural networks to make accurate predictions about what should come after your prompt.\n",
    "\n",
    "Usually, the more parameters a model has, the more human-like it seems.  The smallest GPT models have around 100M parameters, and the largest have 176B.  The model uses the parameters to transform your input - usually by adding the parameters to your input, or multiplying your input by the parameters.  By doing this repeatedly across several layers, the model generates predictions.\n",
    "\n",
    "By the end of this course, you'll understand how to train deep neural networks that work like GPT.  This course is broadly split up into three parts:\n",
    "\n",
    "1. Understanding deep learning - how to create and train deep neural networks, including gradient descent and backpropagation.\n",
    "2. Deep learning for NLP - deep learning architectures to work with text, including RNNs, encoder/decoders, attention, and transformers.\n",
    "3. Scaling up models - putting together the building blocks to train a model with a large number of parameters.\n",
    "\n",
    "In the rest of this lesson, we'll cover some basics that you'll need to understand to start the course.  We'll be implementing all of our models using Python.  If you're not familiar with Python, [here's](https://www.dataquest.io/course/introduction-to-python/) a free Python course that will teach you the basics.\n",
    "\n",
    "Neural networks use matrix operations to apply their parameters to input data.  In Python, the NumPy package enables us to do these operations.  If you already know how to use NumPy, you can skip to the next lesson.  If not, let's learn some fundamentals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy fundamentals\n",
    "\n",
    "This section will assume that you know Python.  If you don't know Python, finish this [free course](https://www.dataquest.io/course/introduction-to-python/) first.\n",
    "\n",
    "NumPy is a Python package that enables us to work with arrays of data more efficiently.  Arrays are similar to lists in Python.\n",
    "\n",
    "To understand why we need NumPy, let's start with one of the fundamental machine learning algorithms, linear regression.  In linear regression, we make a prediction using the equation $\\hat{y} = wx + b$.  In deep learning, we call $w$ the weight, and $b$ the bias.\n",
    "\n",
    "Let's say that we want to predict tomorrow's temperature using three data points from today - today's max temperature, today's min temperature, and how much it rained today.\n",
    "\n",
    "Let's read in our dataset using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "      <th>rain</th>\n",
       "      <th>tmax_tomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-01-01</th>\n",
       "      <td>60.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-02</th>\n",
       "      <td>52.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-03</th>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-04</th>\n",
       "      <td>53.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-01-05</th>\n",
       "      <td>52.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tmax  tmin  rain  tmax_tomorrow\n",
       "1970-01-01  60.0  35.0   0.0           52.0\n",
       "1970-01-02  52.0  39.0   0.0           52.0\n",
       "1970-01-03  52.0  35.0   0.0           53.0\n",
       "1970-01-04  53.0  36.0   0.0           52.0\n",
       "1970-01-05  52.0  35.0   0.0           50.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the data\n",
    "data = pd.read_csv(\"../data/clean_weather.csv\", index_col=0)\n",
    "# Fill in any missing values in the data with past values\n",
    "data = data.ffill()\n",
    "\n",
    "# Show the first 5 rows of the data\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the table above, tomorrow's temperature is `tmax_tomorrow`, today's max temperature is `tmax`, today's min temperature is `tmin`, and how much it rained today is `rain`.\n",
    "\n",
    "We have data from `1970` to the present.  With linear regression, we can extend our equation to multiple predictors like this:\n",
    "\n",
    "$$\\hat{y} = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + b$$\n",
    "\n",
    "So to get a prediction for tomorrow's temperature $\\hat{y}$, we can take a value called $w_{1}$, and multiply it by `tmax`, then take $w_{2}$ and multiply it by `tmin`, then take $w_{3}$ and multiply it by `rain`.  We'd then add in $b$.  Here's how that could look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ".7 * 60 + .3 * 35 + .1 * 0 + 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above could be our prediction for the first row of the data, if our $w$ values are `.7`, `.3`, and `.1`, and our $b$ value is `10`.  We'll discuss how you can calculate the correct $w$ and $b$ values in the next lesson, but for now, let's just use these values.\n",
    "\n",
    "Whenever we want to make a new prediction, we apply the same equation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.099999999999994"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = .7\n",
    "w2 = .3\n",
    "w3 = .1\n",
    "b = 10\n",
    "\n",
    "w1 * 52 + w2 * 39 + w3 * 0 + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Multiplication\n",
    "\n",
    "What if instead of 3 predictor variables (`tmax`, `tmin`, and `rain`), we had `10`?  Or `100`?  It would get annoying to keep track of that many individual $w$ values.\n",
    "\n",
    "Luckily, we can use linear algebra to help us out.  Matrix multiplication is a linear algebra operation defined like this:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    A \\times B =\n",
    "    \\begin{bmatrix}\n",
    "      a_{11} & a_{12} \\\\\n",
    "      a_{21} & a_{22}\n",
    "    \\end{bmatrix}\n",
    "    \\times\n",
    "    \\begin{bmatrix}\n",
    "    b_{11} \\\\\n",
    "    b_{21}\n",
    "    \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix}\n",
    "      a_{11}b_{11} + a_{12}b_{21} \\\\\n",
    "      a_{21}b_{11} + a_{22}b_{21}\n",
    "    \\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "We can visualize how it works with this gif:\n",
    "\n",
    "![Matrix mult](images/intro/matrix_mult.gif)\n",
    "\n",
    "As you can see, we essentially take each row of matrix A and multiply it by each column of matrix B, then add everything together.  The number of columns in the first matrix has to equal the number of rows in the second matrix.\n",
    "\n",
    "This is very useful to us when we're multiplying weights by input numbers.  We can take our $x$ values, put them into a matrix, then multiply by the weights (also in a matrix):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([[60., 35.,  0.],\n       [52., 39.,  0.],\n       [52., 35.,  0.]])"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the first 3 rows of data into a numpy matrix from a pandas dataframe\n",
    "# the first column of the matrix is tmax, second is tmin, third is rain\n",
    "\n",
    "x = data[[\"tmax\", \"tmin\", \"rain\"]].iloc[:3].to_numpy()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.7, 0.3, 0.1])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a matrix with our weights\n",
    "\n",
    "w = np.array([.7, .3, .1])\n",
    "\n",
    "w"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can verify the shapes of our matrices to make sure they can be multiplied:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 3)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape (number of rows and columns) in x\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "(3,)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the shape of w\n",
    "w.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, `x` is a matrix with `3` rows and `3` columns.  `w` is actually a vector with `3` columns.  A vector is known as a one-dimensional array, because it only has length in a single dimension.\n",
    "\n",
    "You can also get arrays with more than 2 dimensions, which we'll work with in later lessons.  Each dimension of the array will have a length corresponding to the size in that dimension.\n",
    "\n",
    "`x` has length `3` in dimension `0` (rows) and dimension `1` columns.  `w` has length `3` in dimension `0`.\n",
    "\n",
    "We'll need to convert `w` from a vector into a matrix to multiply our two matrices.  To do that, we can use the numpy `reshape` method.  We pass in our desired lengths in each dimension:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.7],\n       [0.3],\n       [0.1]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape w into a 3 by 1 matrix\n",
    "# The new dimensions must match the number of elements in w\n",
    "w = w.reshape(3,1)\n",
    "w"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 1)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now have a `3x3` matrix, and a `3x1` matrix.  Since the number of columns in `x` matches the number of rows in `w`, we can multiply them:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[52.5],\n       [48.1],\n       [46.9]])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x @ w"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can now add in our $b$ value, `10`.  $b$ is just a single number.  When we add it to `x @ w`, it will be broadcasted across the matrix (added to each element):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[62.5],\n       [58.1],\n       [56.9]])"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.array([10])\n",
    "x @ w + b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This gives us the same results as when we manually multiplied our `w` and `x` values:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "62.5"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = .7\n",
    "w2 = .3\n",
    "w3 = .1\n",
    "b = 10\n",
    "\n",
    "w1 * 60 + w2 * 35 + w3 * 0 + b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is the power of matrix multiplication - it enables us to store all of our parameters ($w$ and $b$ values) into arrays and then use them to modify our inputs.  This is a lot faster than keeping track of each individual variable!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Matrix Transposition\n",
    "\n",
    "Sometimes we'll need to swap dimensions in a matrix.  This is called matrix transposition.  For example, another way to multiply each row in `x` by each weight is to multiply the transposed weights by the transposed x values:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[62.5, 58.1, 56.9]])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use .T to get the transpose of a matrix\n",
    "w.T @ x.T + b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Transposition takes the `3x1` weight matrix, and turns it into a `1x3` matrix.  It then transposes the `3x3` x matrix.  The dimensions of x will stay the same, but transposition will switch the rows and columns:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.7, 0.3, 0.1]])"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x.T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "`w.T @ x.T` will multiply each column in the weight matrix by each row in the x matrix.  This is the exact same thing that will happen when we do `x @ w`.  It's just that `w.T @ x.T` returns a `1x3` matrix, and `x @ w` returns a `3x1` matrix.  So we need to do another transposition to correct this:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The numpy allclose function tells us if two matrices are approximately equal\n",
    "np.allclose((w.T @ x.T).T, x @ w)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Above, we use `np.allclose` to ensure that both multiplications return the same result.  When comparing the results of matrix multiplication we usually use `np.allclose` instead of `==` because the way computers represent floating point numbers can cause the same number to appear slightly differently.  You can see an explanation for this [here](https://floating-point-gui.de/)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Broadcasting\n",
    "\n",
    "Earlier, we used broadcasting to add the bias `b` to the result of `x @ w`.  Broadcasting enables arrays with compatible shapes to be added or multiplied.\n",
    "\n",
    "If shapes are compatible, it means that:\n",
    "* The smaller array has all of its dimensions exactly matching the length dimensions of the larger array\n",
    "* Or the smaller array is length 1 in the non-matching dimensions.\n",
    "\n",
    "Here are some examples:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.],\n       [2.],\n       [2.],\n       [2.],\n       [2.]])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.ones enables us to create an array filled with ones of a certain shape\n",
    "\n",
    "A = np.ones((5,1))\n",
    "\n",
    "# This works\n",
    "A + np.ones((1,1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.],\n       [2.],\n       [2.],\n       [2.],\n       [2.]])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This works\n",
    "A + np.ones((1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,1) (2,1) ",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# This does not work\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[43mA\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mones\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mValueError\u001B[0m: operands could not be broadcast together with shapes (5,1) (2,1) "
     ]
    }
   ],
   "source": [
    "# This does not work\n",
    "A + np.ones((2,1))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also use broadcasting to multiply individual elements:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[2.],\n       [2.],\n       [2.],\n       [2.],\n       [2.]])"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.full initializes an array filled with a given value\n",
    "# Using the * means that each element in array b is multiplied by the elements in array b\n",
    "A * np.full((1,1), 2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.2914633 ],\n       [0.01636648],\n       [0.76208483],\n       [0.29940725],\n       [0.68891713]])"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.rand generates random numbers between 0 and 1 of a given shape\n",
    "A * np.random.rand(5,1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scalar Math\n",
    "\n",
    "Arrays can also be modified by scalars (single numbers):"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[5.],\n       [5.],\n       [5.],\n       [5.],\n       [5.]])"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.zeros creates an array filled with zeros\n",
    "# We then add 5 to each value in the array\n",
    "np.zeros((5,1)) + 5"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Array Indexing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In NumPy, we can refer to individual elements in arrays using their index.  Indexing starts at 0, just like with Python lists:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "0.05231475596474222"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a 3-dimensional array\n",
    "B = np.random.rand(2,2,2)\n",
    "\n",
    "# Select a single element\n",
    "B[0,1,1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.71004469, 0.05231476])"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a slice from dimension 2 (the last dimension)\n",
    "\n",
    "B[0,1,:]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.77014275, 0.42819339],\n       [0.71004469, 0.05231476]])"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select a 2-d slice from the last 2 dimensions\n",
    "B[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[0.77014275],\n        [0.71004469]],\n\n       [[0.78385723],\n        [0.47675139]]])"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select up to 1 element from the last element\n",
    "B[:,:,:1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also assign to elements using indexing:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[[5.        , 5.        ],\n        [0.71004469, 0.05231476]],\n\n       [[0.78385723, 0.77977957],\n        [0.47675139, 0.98973002]]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0,0,:] = 5\n",
    "B"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrap-up\n",
    "\n",
    "In the next lesson, we'll build on what we learned here to automatically calculate the correct $w$ and $b$ values for linear regression.  This is a key building block of neural networks called gradient descent.  I hope to see you there!"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
